
Tensorflow Keras
This notebook shows how to solve a trivial problem by creating a network using tf.keras

Import the needed modules
In [1]:
import numpy as np
import tensorflow as tf
import random
from matplotlib import pyplot as plt
import seaborn as sns

sns.set()
Define the connections of the nodes in the network
In [2]:
input_ = tf.keras.layers.Input(shape=(2,))
dense1 = tf.keras.layers.Dense(32, activation='relu')(input_)
dense2 = tf.keras.layers.Dense(32, activation='relu')(dense1)
output = tf.keras.layers.Dense(1)(dense2)
Define a model from the input node to the last dense node
In [3]:
model = tf.keras.Model(inputs=input_, outputs=output)
Verify the structure of the created model
In [4]:
model.summary()
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 2)]               0         
_________________________________________________________________
dense (Dense)                (None, 32)                96        
_________________________________________________________________
dense_1 (Dense)              (None, 32)                1056      
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 33        
=================================================================
Total params: 1,185
Trainable params: 1,185
Non-trainable params: 0
_________________________________________________________________
Compile the model by providing the optimization algorithm and the loss function
In [5]:
model.compile('adam', 'mse')
Define the non linear toy problem to check if the network will work
In [6]:
def function(x, y):
    return 5*x**2 - 3*y**2 + 3
Generate random values and calculate the label using the toy problem
In [7]:
X = np.random.rand(100, 2)
y = function(X[:,0], X[:,1])
View the generated values
In [8]:
X[:, 0] # access first column
Out[8]:
array([0.54928248, 0.20868922, 0.74552345, 0.44084309, 0.30936814,
       0.42306707, 0.93163173, 0.42485998, 0.41418389, 0.68148957,
       0.96334715, 0.54972235, 0.6978896 , 0.26184856, 0.35055807,
       0.90451376, 0.38171829, 0.90785666, 0.38251831, 0.28313551,
       0.44987941, 0.90616462, 0.70485067, 0.794274  , 0.03293274,
       0.61243782, 0.8741233 , 0.71881577, 0.25289257, 0.74640453,
       0.47755774, 0.54199035, 0.32814272, 0.19538408, 0.43859735,
       0.28535832, 0.60146835, 0.04313812, 0.92950125, 0.88638178,
       0.12298501, 0.41052209, 0.89607589, 0.44046191, 0.71961982,
       0.75287649, 0.18055196, 0.50610339, 0.64227801, 0.08526456,
       0.14734024, 0.46581502, 0.03883584, 0.33540837, 0.09382603,
       0.49371364, 0.79232143, 0.28987938, 0.91725401, 0.88348217,
       0.47155896, 0.28657249, 0.94210152, 0.59671136, 0.98973202,
       0.4251618 , 0.9036896 , 0.9880702 , 0.15439522, 0.79150767,
       0.54669284, 0.04959837, 0.53322651, 0.44905733, 0.32106488,
       0.48975597, 0.44407209, 0.53244718, 0.93638049, 0.71324789,
       0.38032606, 0.97488481, 0.23598568, 0.91925659, 0.36188732,
       0.37527869, 0.11112323, 0.22853434, 0.63080518, 0.59653851,
       0.5857461 , 0.07333466, 0.71402111, 0.01712511, 0.67196041,
       0.66005895, 0.30977154, 0.96615928, 0.80890187, 0.9487829 ])
In [9]:
X[:, 1] # access second column
Out[9]:
array([0.89457667, 0.33345417, 0.2159322 , 0.43516961, 0.93594126,
       0.55720817, 0.30862149, 0.06511094, 0.42459556, 0.2117447 ,
       0.2926782 , 0.01416978, 0.64212149, 0.21027754, 0.51294101,
       0.16576241, 0.94357241, 0.56149816, 0.02231407, 0.21979353,
       0.66013624, 0.47316605, 0.93205987, 0.62894752, 0.67183382,
       0.61038923, 0.4036349 , 0.25445307, 0.82184075, 0.65264721,
       0.04873236, 0.83477022, 0.55190909, 0.38005154, 0.31165238,
       0.04555714, 0.39597483, 0.43143473, 0.35106722, 0.73513416,
       0.18554198, 0.59745234, 0.45817183, 0.23714729, 0.48041908,
       0.8460475 , 0.00424039, 0.28858274, 0.78262814, 0.26505288,
       0.24070665, 0.18077824, 0.4745802 , 0.84153427, 0.78664797,
       0.10926681, 0.43180324, 0.65089057, 0.52731701, 0.36984259,
       0.41929214, 0.7315249 , 0.89144154, 0.18082916, 0.1217907 ,
       0.50662858, 0.97469041, 0.53838187, 0.12670482, 0.01070232,
       0.3052675 , 0.6884815 , 0.39954328, 0.98005459, 0.57500604,
       0.5687327 , 0.38372868, 0.8544317 , 0.98180721, 0.05312585,
       0.15247872, 0.1966069 , 0.02913908, 0.68396094, 0.91741258,
       0.67011616, 0.68404962, 0.52872605, 0.87624235, 0.3591842 ,
       0.68974224, 0.68339744, 0.05074874, 0.34852107, 0.70076636,
       0.01018422, 0.83871035, 0.75230027, 0.089255  , 0.42456856])
In [10]:
y
Out[10]:
array([2.10775397, 2.88418091, 5.63914596, 3.40359538, 0.85058509,
       2.96348591, 7.0539467 , 3.8898117 , 3.31689731, 5.18763273,
       7.38320709, 4.51037096, 4.19828948, 3.21017342, 2.82512936,
       7.00829414, 1.05755759, 6.17517804, 3.73010753, 3.25590099,
       2.70461785, 6.43401328, 2.87786552, 4.96763098, 1.65134077,
       3.75767539, 6.33169428, 5.38924145, 1.29350662, 4.50775349,
       4.13318243, 2.37824374, 2.62457728, 2.75755718, 3.67045655,
       3.40092051, 4.33843269, 2.4508967 , 6.95011831, 5.30709661,
       2.97234908, 2.77179405, 6.38499575, 3.80131696, 4.89685598,
       3.68672593, 3.1629411 , 4.03086322, 3.2250848 , 2.82559113,
       2.93472666, 3.98687585, 2.33186203, 1.43795412, 1.18757152,
       4.18294806, 5.57950409, 2.14917467, 6.37258493, 6.49235312,
       3.58442157, 1.80523291, 5.05377233, 4.68222469, 7.85334838,
       3.1337952 , 4.23321023, 7.01184852, 3.07102709, 6.1320783 ,
       4.2148006 , 1.59027966, 3.94274804, 1.12674144, 2.52351745,
       3.22893389, 3.54425701, 2.22733937, 4.4922059 , 5.5351457 ,
       3.65349028, 7.63603919, 3.27589895, 5.82175566, 1.12987461,
       2.35700348, 1.65797021, 2.42248601, 2.68617386, 4.3922511 ,
       3.28825942, 1.6257937 , 5.5414044 , 2.63706554, 3.78443347,
       5.17807796, 1.36948687, 5.96945165, 6.24771182, 6.96016962])
In [11]:
model.fit(X, y, batch_size=4, epochs=100)
Train on 100 samples
Epoch 1/100
100/100 [==============================] - 0s 5ms/sample - loss: 16.8358
Epoch 2/100
100/100 [==============================] - 0s 919us/sample - loss: 13.5268
Epoch 3/100
100/100 [==============================] - 0s 943us/sample - loss: 9.5916
Epoch 4/100
100/100 [==============================] - 0s 783us/sample - loss: 5.5157
Epoch 5/100
100/100 [==============================] - 0s 975us/sample - loss: 3.0192
Epoch 6/100
100/100 [==============================] - 0s 803us/sample - loss: 2.2523
Epoch 7/100
100/100 [==============================] - 0s 922us/sample - loss: 1.9222
Epoch 8/100
100/100 [==============================] - 0s 909us/sample - loss: 1.5379
Epoch 9/100
100/100 [==============================] - 0s 1ms/sample - loss: 1.2296
Epoch 10/100
100/100 [==============================] - 0s 770us/sample - loss: 0.9789
Epoch 11/100
100/100 [==============================] - 0s 961us/sample - loss: 0.7885
Epoch 12/100
100/100 [==============================] - 0s 828us/sample - loss: 0.6071
Epoch 13/100
100/100 [==============================] - 0s 956us/sample - loss: 0.4505
Epoch 14/100
100/100 [==============================] - 0s 881us/sample - loss: 0.3573
Epoch 15/100
100/100 [==============================] - 0s 826us/sample - loss: 0.2976
Epoch 16/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.2560
Epoch 17/100
100/100 [==============================] - 0s 992us/sample - loss: 0.2366
Epoch 18/100
100/100 [==============================] - 0s 878us/sample - loss: 0.2218
Epoch 19/100
100/100 [==============================] - 0s 937us/sample - loss: 0.2159
Epoch 20/100
100/100 [==============================] - 0s 852us/sample - loss: 0.2166
Epoch 21/100
100/100 [==============================] - 0s 842us/sample - loss: 0.2028
Epoch 22/100
100/100 [==============================] - 0s 957us/sample - loss: 0.1975
Epoch 23/100
100/100 [==============================] - 0s 855us/sample - loss: 0.1971
Epoch 24/100
100/100 [==============================] - 0s 672us/sample - loss: 0.1960
Epoch 25/100
100/100 [==============================] - 0s 878us/sample - loss: 0.1906
Epoch 26/100
100/100 [==============================] - 0s 735us/sample - loss: 0.1881
Epoch 27/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.1867
Epoch 28/100
100/100 [==============================] - 0s 748us/sample - loss: 0.1846
Epoch 29/100
100/100 [==============================] - 0s 908us/sample - loss: 0.1880
Epoch 30/100
100/100 [==============================] - 0s 940us/sample - loss: 0.1779
Epoch 31/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.1769
Epoch 32/100
100/100 [==============================] - 0s 874us/sample - loss: 0.1757
Epoch 33/100
100/100 [==============================] - 0s 938us/sample - loss: 0.1745
Epoch 34/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.1747
Epoch 35/100
100/100 [==============================] - 0s 2ms/sample - loss: 0.1816
Epoch 36/100
100/100 [==============================] - 0s 2ms/sample - loss: 0.1688
Epoch 37/100
100/100 [==============================] - 0s 2ms/sample - loss: 0.1642
Epoch 38/100
100/100 [==============================] - 0s 2ms/sample - loss: 0.1626
Epoch 39/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.1552
Epoch 40/100
100/100 [==============================] - 0s 872us/sample - loss: 0.1590
Epoch 41/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.1521
Epoch 42/100
100/100 [==============================] - 0s 2ms/sample - loss: 0.1483
Epoch 43/100
100/100 [==============================] - 0s 2ms/sample - loss: 0.1519
Epoch 44/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.1468
Epoch 45/100
100/100 [==============================] - 0s 2ms/sample - loss: 0.1461
Epoch 46/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.1435
Epoch 47/100
100/100 [==============================] - 0s 925us/sample - loss: 0.1353
Epoch 48/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.1316
Epoch 49/100
100/100 [==============================] - 0s 2ms/sample - loss: 0.1313
Epoch 50/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.1298
Epoch 51/100
100/100 [==============================] - 0s 2ms/sample - loss: 0.1228
Epoch 52/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.1207
Epoch 53/100
100/100 [==============================] - 0s 962us/sample - loss: 0.1191
Epoch 54/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.1161
Epoch 55/100
100/100 [==============================] - 0s 876us/sample - loss: 0.1179
Epoch 56/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.1104
Epoch 57/100
100/100 [==============================] - 0s 904us/sample - loss: 0.1114
Epoch 58/100
100/100 [==============================] - 0s 799us/sample - loss: 0.1073
Epoch 59/100
100/100 [==============================] - 0s 829us/sample - loss: 0.1025
Epoch 60/100
100/100 [==============================] - 0s 865us/sample - loss: 0.1023
Epoch 61/100
100/100 [==============================] - 0s 954us/sample - loss: 0.0967
Epoch 62/100
100/100 [==============================] - 0s 821us/sample - loss: 0.0999
Epoch 63/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.0938
Epoch 64/100
100/100 [==============================] - 0s 891us/sample - loss: 0.0905
Epoch 65/100
100/100 [==============================] - 0s 937us/sample - loss: 0.0909
Epoch 66/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.0929
Epoch 67/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.0878
Epoch 68/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.0867
Epoch 69/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.0843
Epoch 70/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.0793
Epoch 71/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.0803
Epoch 72/100
100/100 [==============================] - 0s 2ms/sample - loss: 0.0747
Epoch 73/100
100/100 [==============================] - 0s 944us/sample - loss: 0.0742
Epoch 74/100
100/100 [==============================] - 0s 820us/sample - loss: 0.0841
Epoch 75/100
100/100 [==============================] - 0s 827us/sample - loss: 0.0728
Epoch 76/100
100/100 [==============================] - 0s 941us/sample - loss: 0.0697
Epoch 77/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.0673
Epoch 78/100
100/100 [==============================] - 0s 753us/sample - loss: 0.0681
Epoch 79/100
100/100 [==============================] - 0s 889us/sample - loss: 0.0699
Epoch 80/100
100/100 [==============================] - 0s 928us/sample - loss: 0.0639
Epoch 81/100
100/100 [==============================] - 0s 778us/sample - loss: 0.0604
Epoch 82/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.0597
Epoch 83/100
100/100 [==============================] - 0s 928us/sample - loss: 0.0574
Epoch 84/100
100/100 [==============================] - 0s 923us/sample - loss: 0.0556
Epoch 85/100
100/100 [==============================] - 0s 868us/sample - loss: 0.0555
Epoch 86/100
100/100 [==============================] - 0s 906us/sample - loss: 0.0521
Epoch 87/100
100/100 [==============================] - 0s 865us/sample - loss: 0.0516
Epoch 88/100
100/100 [==============================] - 0s 858us/sample - loss: 0.0507
Epoch 89/100
100/100 [==============================] - 0s 971us/sample - loss: 0.0506
Epoch 90/100
100/100 [==============================] - 0s 881us/sample - loss: 0.0445
Epoch 91/100
100/100 [==============================] - 0s 861us/sample - loss: 0.0485
Epoch 92/100
100/100 [==============================] - 0s 870us/sample - loss: 0.0460
Epoch 93/100
100/100 [==============================] - 0s 815us/sample - loss: 0.0471
Epoch 94/100
100/100 [==============================] - 0s 852us/sample - loss: 0.0434
Epoch 95/100
100/100 [==============================] - 0s 871us/sample - loss: 0.0414
Epoch 96/100
100/100 [==============================] - 0s 791us/sample - loss: 0.0387
Epoch 97/100
100/100 [==============================] - 0s 992us/sample - loss: 0.0388
Epoch 98/100
100/100 [==============================] - 0s 942us/sample - loss: 0.0381
Epoch 99/100
100/100 [==============================] - 0s 1ms/sample - loss: 0.0388
Epoch 100/100
100/100 [==============================] - 0s 919us/sample - loss: 0.0362
Out[11]:
<tensorflow.python.keras.callbacks.History at 0x7f4b24048990>
Predict the label using the model and verify the result
In [12]:
predictions = model.predict(X)
In [13]:
predictions[:5] # first 5 rows
Out[13]:
array([[2.2167451],
       [2.9072351],
       [5.84826  ],
       [3.5800223],
       [1.2372991]], dtype=float32)
In [14]:
y[:5] # first 5 rows
Out[14]:
array([2.10775397, 2.88418091, 5.63914596, 3.40359538, 0.85058509])
In [15]:
def plot_3d(x, y, z, size):
    fig = plt.figure(figsize=size)
    ax = fig.add_subplot(111, projection='3d')
    ax.scatter(x, y, z)
    plt.show()
In [16]:
plot_3d(X[:, 0], X[:, 1], y, (15, 10))

In [17]:
plot_3d(X[:, 0], X[:, 1], predictions[:, 0], (15, 10))

The loss can also be calculated using the evaluate function
In [18]:
model.evaluate(X, y)
100/100 [==============================] - 0s 1ms/sample - loss: 0.0365
Out[18]:
0.03652567736804485
